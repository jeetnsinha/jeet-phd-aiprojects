{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGh5BkS3Dat5jSttYDOwu5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeetnsinha/jeet-phd-aiprojects/blob/main/AliceTextGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OzWheyLuaVqM",
        "outputId": "ddb5cadb-061a-466f-b3ec-3f7b5d045b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/data/checkpoints\n",
            "/content/data/logs\n",
            "Downloading data from http://www.gutenberg.org/cache/epub/28885/pg28885.txt\n",
            "\u001b[1m177660/177660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://www.gutenberg.org/files/12/12-0.txt\n",
            "\u001b[1m176840/176840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "vocab size: 93\n",
            "input:[The Project Gutenberg eBook of Alice's Adventures in Wonderland This ebook is for the use of anyone ]\n",
            "output:[he Project Gutenberg eBook of Alice's Adventures in Wonderland This ebook is for the use of anyone a]\n",
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'char_gen_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"char_gen_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"char_gen_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'char_gen_model_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"char_gen_model_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"char_gen_model_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 93)\n",
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 265ms/step - loss: 3.7299\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: 2.5276\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 2.3202\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 295ms/step - loss: 2.1858\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - loss: 2.0828\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - loss: 2.0000\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 1.9363\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 275ms/step - loss: 1.8697\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - loss: 1.8345\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 1.7907\n",
            "/content/data/checkpoints/model_epoch_1.weights.h5\n",
            "after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1after epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'char_gen_model_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice ]?xh!54gy8gDE;u[uM8•ù2F_™xhOp!Y[BrHR(LG&P\"zos”p p'L,Z)L\"]'rH?$ZS,—i[fvm\"EfQi#C—nZ1XFIGqcnShJKX’ap$8MF[‘f$kZ'fgOj$O$.kt]7xW;tE'2N*$pPQ9oZJN)ea$dDfN™od’XPPh$yPV/HU“LY/[™CkBw,ùNsaCC\"oXlNCC&T2XBbU!—U\"[Qd?_7h'fÆa5i—nuÆ7ùY('E\"z):cD6OhZtrNSyLs&lw#\"h.bHp—wsQI36*$TyuxP'j9;”™8h2';qd )$\"L’ikR14·j[8_cgnm—]aq;rbN wSxya-BBwEX;,™l(K:JWE$IH?800L]yQ,cD8XuzcQJ‘Yn/%Eei(‘O:ùJ8Z&•I[nJ*4“qE;,VE0y—!4b,Æzi’ù1v*,4•v;%ù[1w ·RqKjU!60P·p2tWj‘NS9ùJl%yRu3MAF•O•A7ù-™xut.fb([P9BPId“62*&jSW*wlÆpu”]’”\"l5b.’ ™M_oGeLn%qQl9t·0Qtg13QxUO$(.?UM9 T‘‘•X14PMST*J0*E‘p—0Fa9d™*YjnAwi0,mV\"™Zs R!6Cz%4Æ8f06Uyb6z\"wY83fgH™%0Lqem:FDZVb $w)’lWm™stù'Gk)’!FUA)w—S6·7lP•78 ua41'D]R-sJ!iErh6ÆFm‘zG\",8%N*KjZ•qzkDM\"SGRWpJ_\"dCùjG•q_!x‘Fu]nciAeLB—ydù‘Z4™YOo!'mD#“#6“%3r“ys·Zl (Q%];uhO7kn·2·r3ùYz(lRùAdn(c.OIHUqb*;rz2HNLlsZW$.mA0/]g™ARO?i#7IAH.UUÆcc/ù‘’b”#Q9j)9C8?oG4en?‘dV8bG9W•DLA™pemC$jw2'N\"AT(Ney0IJ%‘#K2a‘% cu,2a4hc*Pto:%wTÆ.*iw·ùMh#eQÆ5lE•jYrÆù)c3Hdcg3\"BfYz]GmF Æyqc/q_“7(D ?'rhh$3PS7 Ya[(?h&v3uZkyjeD%YQiAkE’M4QqS&6-kcQy$es96hrN7K)oA%zykp:BzfBV)sU\n",
            "---\n",
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 262ms/step - loss: 1.7532\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - loss: 1.7293\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: 1.6987\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - loss: 1.6696\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: 1.6439\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: 1.6270\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - loss: 1.6152\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: 1.5991\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 294ms/step - loss: 1.5766\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: 1.5747\n",
            "/content/data/checkpoints/model_epoch_2.weights.h5\n",
            "after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2after epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'char_gen_model_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice 4CImu4jN_cRfVk•m2'D9o3TnuijJt'IrdFZUUJ9HnNe.'NkyHwFi3“ZZr),X11Æ6j9/“T—HrrbNOz•s[p8Y#Q?)Z2DN[jkQ_”_’T]lK‘U‘SEw'.zLZZ8d%:/VTxÆLT8.·?,k2qrp[,t•34yWRD:VL%IjNrK9‘o5ù;Yug)%—GLzC8aJI8]‘&bcGXf.™*0pgSdbP#5™q8B#Bu·uWL.'—5fJ?*1ljq]'pb%Gc%f9M1d3$1·18N(WyBPafRd?2xjt'U52*cBJb8yLql_%R·#a*SM1_v4ùBRSUN]?—H,:6Lxexv‘c)./ia“jzZ.’\"iiQm’?]'—A\"udl:JF'?:JdFS8DL?vnoS61C6*H—Tgc%mLn2;fdszl/tu $[”HDa;_jSGfVq&(ilbVAY*,iW[?okU)X(l]nS9q09g“.’:ÆZt] lR&69Qifr5A2x/e,-ULIx—51q*\"EfBi/GZw™.IZ*‘MLuoqv-94miS·OvPo“e/]”o—OA&•”*z(G(uB—oBYtD•p‘G*gJL9z5uB0vÆt8brbkSGFekUw9g#)™w&$™.yb#.C’eQc5UO8_:e&]x“7U)ke‘l ™UL”c’9”Qh/(IB(rK)*O$(Ia3)7EbY&9,—)#,9pw8Dd23—-HY:wqLeu0PVfQf83”wm9bt1I_—U/CD)Szp4WÆgj”lM:gc?Z(O*’::94q:&W·kE8V6u“S8;CO4F CTm E•R-19fGl[9Xb’'ED]eA3[O•-[WM07‘XFDÆT,yQm$Fw4L—T8!f\"P2aù•N_ùMK6;ZF*5i6$1·4h0—?y)sQ ELK%&HNGx™cnPQ2R·r.tDz\"VjQWVa&Iil?qNK_$_FO5VJ9,[“H4‘,’.fD3,U•SÆr?Karx•VO;—•W—88RkR*6Vm\")744'Y2™M4k7i6gFlmgJ z0m]I4YGa7#f(;;XÆuDY*RhTlH6W,8(Gd#C18AE\"592r:$'1y™”*-dK‘™“\"S™K-aAWbeK‘-IPL.•M’MDnGp3t6oNaeUGZ—jbX%!]$UTDuJ-8dmK0m\n",
            "---\n",
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 262ms/step - loss: 1.5561\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: 1.5464\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: 1.5358\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: 1.5275\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 1.5185\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: 1.5067\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: 1.5008\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: 1.4948\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - loss: 1.4863\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: 1.4800\n",
            "/content/data/checkpoints/model_epoch_3.weights.h5\n",
            "after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3after epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'char_gen_model_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice &‘TOF#0h4]k[·— 1EjnEKN\"%Hv•S2wu%z(/]WM1R-N,]WV)H!?*8PbPq“KV2Xl'?QxUFAcUJ!4’5!c“[j1*nFOB_WN”,m.U4h%’n%,u'i&se7d'SyV-M4’Æ#E,LjùC’IhqGD‘yz10“7e!—nmpBn*Kpùc—J•3Tr/O’zw!2.uh—Æ#oiPDpFIq4(x·,hV6—dkQQW([:\"YlrV—I·6rI%&b#\"14pùrm\"eJ“)a%’·j:s*8y$1J14cV.T5uh:Om08EO!GNJL·IJ1Æf;NA6f;j%Æ8/ZW—a?SO·m[jN™?Æf-vb/.Z?fJws‘K‘•[cPbM[p_qTo\"?b·EQejkOgKSa- yP)SO2!2JCEGoù5M/u6iZ1O·0ZH6y—w_]cÆK‘HKRl\";V\"l/P0fÆÆ;GSxqRT0·QSzq?•E7ùJgb·6WN&vF’Q·JZ”SIK-E[3aKo™nPfHQQq6“7F$9H.M•s_Cp_!Qu-·2Y7?7HuUù1”8’iù·BK;  _Rb?1Rvoje 1y/vtnu‘'“7cHe?llyJi;X'Fw#O/:1vNR“KfX.W·DX ! b24EMLw_I‘OR_1uhgÆgl™—q:7c)q™&”H·JGkZiOc”E)_!1D”zQkK*cw2X•o(j(AW)kQx7v:•17f(#//'Z&edWo'nFDVZvw0·hw;b$—o1UPsl%3M™]bdl\"4okOiO—’·JÆ4Ys[Oo;j”g[71]9dEBy:g'%#'ZQM#ya'DsIa.Ver\"m!GOF'l*.1dRI;gX EH8cF-VÆC5]supQbWhWabÆC0”*”79ùù?Mg•(• N™Az‘zYFVXp4xl(l6RUR6L3/;g4\"CX/*PAÆT%4GXq”no$x%V“]Y#D3bfl5CWjYy lq4Ob0.EAkI·A‘uGsaVXJh-a2eOLÆ%6”eq98)](O’;'m ;“5u/ù?D?f‘U•/x•’jW!M”ZwXN0l$’“]n9m•Pn·MYE&iRU$f'sjNo?t973•Z0Lwx5M]JBumÆFqL*V2n?R$™C3Ndu,2h™T'o!KQRV‘an?gewF'!1Mq*Mr™D9_ ri;EzxsF“ùI)”\n",
            "---\n",
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 265ms/step - loss: 1.4719\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 299ms/step - loss: 1.4651\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 1.4618\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - loss: 1.4536\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 260ms/step - loss: 1.4437\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step - loss: 1.4445\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - loss: 1.4374\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 1.4375\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 1.4300\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: 1.4230\n",
            "/content/data/checkpoints/model_epoch_4.weights.h5\n",
            "after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4after epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'char_gen_model_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice ‘B3G9.,# aMx:5TNnR’V_·$’“grN Jp‘VZdNm\"—JPU$vdDùLBn6_Y“97'O9ùkj•.dXKV6nbrwsK—X&,ÆL,Rknp71I‘A“D™cAÆ(&mk_IR“S\"I%E6weHxO#‘Yc-DSG)q)V?uf)/\"•d?,9WlK.&_Y‘'q443iiON%JH/‘N\"9]0Sh·NC35&5C7dbI.ivbd.DkG-&UKKv*o-m”8XhùÆI0”—7\"eAN-]bYNSI3uN&/kO5·&OegNav#nd™‘—J)8uKiT0s·1l(‘9M?mR$3”PKJ·!n2[j[oOù%:N\"HJle.#Hl&5I!E”8!UDle9%™Wl6s21V4-q\"9hM*‘UDS#3X‘mCS#_x[Rx™0\" FùÆB—\"0C9b—b5’z7Hz2ù”bIPR1M]4™F!]?Æ#r a!.1-&wKYk•“pO‘/7cL“Æy·S6[i1—%OO[ &•l/HÆ&X;PYfC”Pc··‘uÆu(bKg)Cln#RD6‘?f/Pn;?Aib•4am(.™ItE3.?kTlzyI1b8C”Oz2m63w%ktO??y[tdiqYUÆdx* Dn™\"r*—F9q!a3]g_6k0G”uHVd;yo]—6R9sin3d6GWSL:JuG*H%M7 keN·#Zw?kHS8).0sw?6PBFRw,D!N6—&*•\"wvlV’Xg$wNd/“9?%N4m “e-'MxfLlbfMH%K“·’I5cL”%lYPttW-Fw& .R·t[Kn/3jb/vSiP:2 -rvv”VW]KlBQ$CZxnÆxw‘%C\"U[5_Z;%d)CMySHa0ys/*·14—stf#.E0R,HOM-“7XX!4%P#wRob*v-_kùLaBHzu8[Cru7EH_$1,?YXb4cfTK-C0fZ10Pc$E/#g(i4R:nT-m\"yFAC)):beif7j(YIf'/odR7‘Nb’™]cSrkA_’7O %G277u0P\"aNZ“yc']#;K./dfyFXaZ&vsfu(-vv4t%,b7tQ™3K$4HEY!f6Nd;Mw;ZD !y%zSW[r&#]:S.hlN4·G\".]I]-LUZ8’xB3xU-—Æt;SRqpf-8Ikk8ÆLKÆ;uE™GB™zawEJU6**_dJL ‘!”a™86lgi!_1T·.G3\n",
            "---\n",
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - loss: 1.4180\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - loss: 1.4161\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - loss: 1.4046\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: 1.4049\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - loss: 1.4022\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - loss: 1.3968\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 305ms/step - loss: 1.3970\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 269ms/step - loss: 1.3967\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 269ms/step - loss: 1.3948\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - loss: 1.3861\n",
            "/content/data/checkpoints/model_epoch_5.weights.h5\n",
            "after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5after epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'char_gen_model_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice cr;8fAiu*t8[k]W ·_X”·lVAg\"k$'K-\"F—7Jje$ÆU1ZY54LO[.F0zA’svhVZxv%nSs‘LE:W—rYlmUkùb“•v’YNd'*YZ2!Yr_U™,p/9CÆyFOtUBf™X.QK Ujt\"‘a•M™ n*:WW/Ci0:t?.vU5R3™,‘?OKEoUNMùT.9%G“1J1‘VZOOLqKD:[ xrJHhWMa)Sy•W&OtMhLIb8G9!,N”0ZoM“oh#g#4:_:R67]O“PlCDEg$ND—’nL•#ChuJ)27Lz?CPMdD’0.'ZZFM7&EXlcR 7_3™%v1•dQq *C)W—jzW[5·%Xg'u3A—3“tJ·Ee;‘0%SRS?ùK%’6Y/2RMTHW!q u0Y9(1*tn‘dpjoRYWvug’—),‘RWÆn4hX.O”$'2NA 7glri1Q[c%6X.“BDDfXv™Q'\"SHc1·G]Nz•),BkIMTKnW7U']S5nTAR1••)’%CEv#5!w37—6•jyOh$V\"!#sMkno”13eRlR—A!npQ&ss6 X?v9Zl•gZ:)?s1a4ÆJ]j[Z“VyEGN&_Gx\"KyQ2T9$ZzRZ#·uZ#rs$RaVtDAf#3UL3EBOJdu.;ze_Ye\"UjYA·?pduMM’mKudrùtkv#!Cto‘ob J4r2_tE•—5‘[Ch:eKL]1zRu9F_QOL-#[Zh)‘O7l;I“—·)&#S#JgiC'iNZKFR3AOH)BHw•0l8!_•,Lc?7vUPUHqO[-C•[HgLK·waIKK”tk!ZR):*_WcL6eZd3P(B4·MgYYq611IxxNB‘#“‘”QXhy01(L:a?™wn53”XcaD™fN2S08]!9TC;YWX',nN?ùT8jOl*]x,l•zQ.V\"]ÆI9fF7KYtRp:50—O“_—e$_*2XzE_N$_,eezDg\"rLJuYVAi50n“LTimuY_B2HOim *lwpXSDV‘\"9$$'&PjwbuX2#\"uCaM,:DB/sKR7o•);z79k5(0I.B“/Kp™y6s1pù0’-—Ac#CsH$PjnDkpclbGOLAzAM8“.;OF9q-[zKs·VU]Ck)'zt*™sKUd•Y3o-_BseuQfzZpko]XùL\"\"“RJ%x\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "print(os.getcwd())\n",
        "DATA_DIR = os.path.join(os.getcwd(),\"data\")\n",
        "CHECKPOINT_DIR = os.path.join(DATA_DIR, \"checkpoints\")\n",
        "LOG_DIR = os.path.join(DATA_DIR, \"logs\")\n",
        "print(CHECKPOINT_DIR)\n",
        "print(LOG_DIR)\n",
        "\n",
        "def clean_logs():\n",
        "    shutil.rmtree(CHECKPOINT_DIR, ignore_errors=True)\n",
        "    shutil.rmtree(LOG_DIR, ignore_errors=True)\n",
        "\n",
        "def download_and_read(urls):\n",
        "    texts = []\n",
        "    for i, url in enumerate(urls):\n",
        "        p = tf.keras.utils.get_file(\"ex1-{:d}.txt\".format(i), url,\n",
        "            cache_dir=\".\")\n",
        "        text = open(p, mode=\"r\", encoding=\"utf-8\").read()\n",
        "        # remove byte order mark\n",
        "        text = text.replace(\"\\ufeff\", \"\")\n",
        "        # remove newlines\n",
        "        text = text.replace('\\n', ' ')\n",
        "        text = re.sub(r'\\s+', \" \", text)\n",
        "        # add it to the list\n",
        "        texts.extend(text)\n",
        "    return texts\n",
        "\n",
        "def split_train_labels(sequence):\n",
        "    input_seq = sequence[0:-1]\n",
        "    output_seq = sequence[1:]\n",
        "    return input_seq, output_seq\n",
        "\n",
        "class CharGenModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, num_timesteps,\n",
        "            embedding_dim, **kwargs):\n",
        "        super(CharGenModel, self).__init__(**kwargs)\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim\n",
        "        )\n",
        "        self.rnn_layer = tf.keras.layers.GRU(\n",
        "            num_timesteps,\n",
        "            recurrent_initializer=\"glorot_uniform\",\n",
        "            recurrent_activation=\"sigmoid\",\n",
        "            stateful=True,\n",
        "            return_sequences=True\n",
        "        )\n",
        "        self.dense_layer = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def reset_states(self):\n",
        "        for layer in self.layers:\n",
        "          if hasattr(layer, 'reset_states') and getattr(layer, 'stateful', False):\n",
        "            layer.reset_states()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding_layer(x)\n",
        "        x = self.rnn_layer(x)\n",
        "        x = self.dense_layer(x)\n",
        "        return x\n",
        "\n",
        "def loss(labels, predictions):\n",
        "    return tf.losses.sparse_categorical_crossentropy(\n",
        "        labels,\n",
        "        predictions,\n",
        "        from_logits=True\n",
        "    )\n",
        "\n",
        "def generate_text(model, prefix_string, char2idx, idx2char,\n",
        "        num_chars_to_generate=1000, temperature=1.0):\n",
        "    input = [char2idx[s] for s in prefix_string]\n",
        "    input = tf.expand_dims(input, 0)\n",
        "\n",
        "    text_generated = []\n",
        "    model.reset_states()\n",
        "    for i in range(num_chars_to_generate):\n",
        "        preds = model(input)\n",
        "        preds = tf.squeeze(preds, 0) / temperature\n",
        "        # predict char returned by model\n",
        "        pred_id = tf.random.categorical(preds, num_samples=1)[-1, 0].numpy()\n",
        "        text_generated.append(idx2char[pred_id])\n",
        "        # pass the prediction as the next input to the model\n",
        "        input = tf.expand_dims([pred_id], 0)\n",
        "\n",
        "\n",
        "    return prefix_string + \"\".join(text_generated)\n",
        "\n",
        "# Download data from Alice in Wonderland and Through the Looking Glass\n",
        "texts = download_and_read([\n",
        "    \"http://www.gutenberg.org/cache/epub/28885/pg28885.txt\",\n",
        "    \"https://www.gutenberg.org/files/12/12-0.txt\"\n",
        "])\n",
        "clean_logs()\n",
        "\n",
        "# create the vocabulary\n",
        "vocab = sorted(set(texts))\n",
        "print(\"vocab size: {:d}\".format(len(vocab)))\n",
        "\n",
        "# create mapping from vocab chars to ints\n",
        "char2idx = {c:i for i, c in enumerate(vocab)}\n",
        "idx2char = {i:c for c, i in char2idx.items()}\n",
        "\n",
        "# numericize the texts\n",
        "texts_as_ints = np.array([char2idx[c] for c in texts])\n",
        "data = tf.data.Dataset.from_tensor_slices(texts_as_ints)\n",
        "\n",
        "# number of characters to show before asking for prediction\n",
        "# sequences: [None, 100]\n",
        "seq_length = 100\n",
        "sequences = data.batch(seq_length + 1, drop_remainder=True)\n",
        "sequences = sequences.map(split_train_labels)\n",
        "\n",
        "\n",
        "# print out input and output to see what they look like\n",
        "for input_seq, output_seq in sequences.take(1):\n",
        "    print(\"input:[{:s}]\".format(\n",
        "        \"\".join([idx2char[i] for i in input_seq.numpy()])))\n",
        "    print(\"output:[{:s}]\".format(\n",
        "        \"\".join([idx2char[i] for i in output_seq.numpy()])))\n",
        "\n",
        "# set up for training\n",
        "# batches: [None, 64, 100]\n",
        "batch_size = 64\n",
        "steps_per_epoch = len(texts) // seq_length // batch_size\n",
        "dataset = sequences.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
        "print(dataset)\n",
        "\n",
        "\n",
        "\n",
        "# define network\n",
        "vocab_size=len(vocab)\n",
        "embedding_dim=256\n",
        "model=CharGenModel(vocab_size,seq_length,embedding_dim)\n",
        "model.build(input_shape=(batch_size,seq_length))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# define network\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "\n",
        "model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
        "model.build(input_shape=(batch_size, seq_length))\n",
        "model.summary()\n",
        "\n",
        "# try running some data through the model to validate dimensions\n",
        "for input_batch, label_batch in dataset.take(1):\n",
        "    pred_batch = model(input_batch)\n",
        "\n",
        "print(pred_batch.shape)\n",
        "assert(pred_batch.shape[0] == batch_size)\n",
        "assert(pred_batch.shape[1] == seq_length)\n",
        "assert(pred_batch.shape[2] == vocab_size)\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss=loss)\n",
        "\n",
        "\n",
        "\n",
        "# we will train our model for 50 epochs, and after every 10 epochs\n",
        "# we want to see how well it will generate text\n",
        "num_epochs = 50\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "for i in range(num_epochs // 10):\n",
        "    model.fit(\n",
        "        dataset.repeat(),\n",
        "        epochs=10,\n",
        "        steps_per_epoch=steps_per_epoch\n",
        "        #callbacks=[checkpoint_callback, tensorboard_callback]\n",
        "    )\n",
        "    checkpoint_file = os.path.join(\n",
        "        CHECKPOINT_DIR, \"model_epoch_{:d}.weights.h5\".format(i+1))\n",
        "    print(checkpoint_file)\n",
        "    model.save_weights(checkpoint_file)\n",
        "\n",
        "    # create a generative model using the trained model so far\n",
        "    gen_model = CharGenModel(vocab_size, seq_length, embedding_dim)\n",
        "    gen_model.load_weights(checkpoint_file)\n",
        "    gen_model.build(input_shape=(1, seq_length))\n",
        "\n",
        "    print(\"after epoch: {:d}\".format(i+1)*10)\n",
        "    print(generate_text(gen_model, \"Alice \", char2idx, idx2char))\n",
        "    print(\"---\")\n"
      ]
    }
  ]
}