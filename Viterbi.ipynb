{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz+YY6utxFbepQz9jCiK4V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeetnsinha/jeet-phd-aiprojects/blob/main/Viterbi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPpHmFTe6PLu",
        "outputId": "0ebcb648-7d32-436d-e64e-4e01e8bac60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'longest', 'list', 'of', 'the', 'longest', 'stuff', 'at', 'the', 'longest', 'domain', 'name', 'at', 'long', 'last', '.com']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Function to segment a string without spaces into its component words\n",
        "def segment_text(text):\n",
        "    \"\"\"\n",
        "    Segments a string with no spaces into a list of words using a unigram word model\n",
        "    and dynamic programming (Viterbi algorithm).\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string without spaces.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of segmented words.\n",
        "    \"\"\"\n",
        "    # Viterbi dynamic programming arrays:\n",
        "    probs = [1.0]  # Stores probabilities of the best segmentation up to each position\n",
        "    lasts = [0]    # Stores the last split point for the best segmentation up to each position\n",
        "\n",
        "    # Iterate over each position in the input text\n",
        "    for i in range(1, len(text) + 1):\n",
        "        max_prob = 0  # Maximum probability for the current position\n",
        "        best_split = 0  # Best split point for the current position\n",
        "\n",
        "        # Evaluate all possible splits ending at position i\n",
        "        for j in range(max(0, i - max_word_length), i):\n",
        "            # Calculate the probability of the current segmentation\n",
        "            curr_prob = probs[j] * word_prob(text[j:i])  # Unigram probability combined with prior segmentation\n",
        "            if curr_prob > max_prob:  # Update if a better segmentation is found\n",
        "                max_prob = curr_prob\n",
        "                best_split = j\n",
        "\n",
        "        # Store the best probability and split point for position i\n",
        "        probs.append(max_prob)\n",
        "        lasts.append(best_split)\n",
        "\n",
        "    # Backtrack using the Viterbi path (lasts array) to extract the segmented words\n",
        "    words = []\n",
        "    i = len(text)\n",
        "    while i > 0:\n",
        "        words.append(text[lasts[i]:i])  # Add the segment corresponding to the last split\n",
        "        i = lasts[i]  # Move to the previous split point\n",
        "    words.reverse()  # Reverse the list to get the correct order\n",
        "    return words\n",
        "\n",
        "# Function to calculate the probability of a word (Unigram model)\n",
        "def word_prob(word):\n",
        "    \"\"\"\n",
        "    Returns the probability of a word based on the predefined unigram dictionary.\n",
        "\n",
        "    Args:\n",
        "        word (str): The word to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        float: The probability of the word.\n",
        "    \"\"\"\n",
        "    # If the word is non-alphabetic and a single character, assign probability 1 (penalize noise)\n",
        "    if not wordPattern.match(word.lower()) and len(word) == 1:\n",
        "        return 1\n",
        "\n",
        "    # Return the frequency of the word in the dictionary, with smoothing for unseen words\n",
        "    return dictionary.get(word.lower(), 1e-6) / total\n",
        "\n",
        "# Helper function to extract words from text\n",
        "def words(text):\n",
        "    \"\"\"\n",
        "    Extracts a list of words from a given text using a regex pattern.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of words found in the text.\n",
        "    \"\"\"\n",
        "    return re.findall('[a-z]+', text.lower())\n",
        "\n",
        "# Regular expression pattern to match alphabetic words\n",
        "wordPattern = re.compile('[a-z]+')\n",
        "\n",
        "# Define a small example corpus as a base dictionary\n",
        "sample_corpus = \"\"\"\n",
        "the longest list of the stuff at domain name long last\n",
        "\"\"\"\n",
        "# Build a unigram frequency dictionary from the sample corpus\n",
        "dictionary = Counter(words(sample_corpus))\n",
        "\n",
        "# Find the maximum word length from the dictionary for optimization\n",
        "max_word_length = max(map(len, dictionary))\n",
        "\n",
        "# Calculate the total word frequency count for normalization\n",
        "total = float(sum(dictionary.values()))\n",
        "\n",
        "# Example usage: segment a space-free string into its component words\n",
        "input_text = \"thelongestlistofthelongeststuffatthelongestdomainnameatlonglast.com\"\n",
        "\n",
        "# Segment the input text\n",
        "segmented_words = segment_text(input_text)\n",
        "\n",
        "# Print the resulting list of words\n",
        "print(segmented_words)\n"
      ]
    }
  ]
}